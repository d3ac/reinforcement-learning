{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "观测空间 O: Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n",
      "动作空间 A: Discrete(3)\n",
      "观测范围 : [-1.2  -0.07] ~ [0.6  0.07]\n",
      "动作数 n: 3\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MountainCar-v0', render_mode=\"human\")\n",
    "print('观测空间 O: {}'.format(env.observation_space))\n",
    "print('动作空间 A: {}'.format(env.action_space))\n",
    "print('观测范围 : {} ~ {}'.format(env.observation_space.low, env.observation_space.high))\n",
    "print('动作数 n: {}'.format(env.action_space.n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BespokeAgent:\n",
    "    def __init__(self, env):\n",
    "        pass\n",
    "\n",
    "    def decide(self, observation):\n",
    "        position, velocity = observation\n",
    "        lower_bound = min(-0.09 * (position + 0.25) ** 2 + 0.03, 0.3 * (position + 0.9) ** 4 - 0.008)\n",
    "        upper_bound = -0.07 * (position + 0.38) ** 2 + 0.07\n",
    "        if lower_bound < velocity and velocity < upper_bound:\n",
    "            return 2 # 返回动作\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def learn(self, *args):\n",
    "        pass\n",
    "\n",
    "agent = BespokeAgent(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_montecarlo(env, agent, render=False, train=False, seed=None):\n",
    "    episode_reward = 0.0\n",
    "    observation, _ = env.reset(seed=seed) # 重置游戏环境, 开始新的一回合\n",
    "    while True:\n",
    "        if render:\n",
    "            env.render()\n",
    "        action = agent.decide(observation)\n",
    "        next_observation, reward, terminated, truncated, _ = env.step(action)\n",
    "        episode_reward += reward\n",
    "        if train:\n",
    "            agent.learn(observation, action, reward, terminated, truncated)\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "        observation = next_observation\n",
    "    return episode_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "回合奖励: -123.0\n"
     ]
    }
   ],
   "source": [
    "# 设置初始化种子, 没有引入时间, 所以同样的数字就可以重现\n",
    "episode_reward = play_montecarlo(env, agent, render=True, seed = 0)\n",
    "print('回合奖励: {}'.format(episode_reward))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均回合奖励 -105.82\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MountainCar-v0') # 不设置 render\n",
    "episode_rewards = [play_montecarlo(env, agent) for _ in range(100)] # 交互 100 回合求平均\n",
    "print(f'平均回合奖励 {np.mean(episode_rewards):.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81e75cef6ba1b10275bdce9a4ca9089c470de9a530eb43eaa03a6734d261d4ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
